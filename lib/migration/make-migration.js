import { validate as validateField } from "../models/fields.js";
import { makeSchemaChangeHandler } from "../schema/basic-js-schema.js";
import { fromSchemaToData } from "../models/models.js";
import { createDiff, applyDiff, reverseDiff } from "../diff/diff.js";

// Determine whether we're running in CJS or ESM mode.
let IS_ESM = false;
try {
  IS_ESM = typeof import.meta !== `undefined`;
} catch (e) {}

/**
 * Make sure we add a run-relevant file system API import.
 */
export function finalizeMigration(script) {
  let fs = IS_ESM ? `import fs from "fs";` : `const fs = require("fs");`;
  script = script.replace(`if (processAll) {`, `${fs}\nif (processAll) {`);
  return `#!/usr/bin/node\n\n${script}`;
}

/**
 * Determine the series of operation transforms to turn schema1 into
 * schema2, and then turn that into a self-executing .js file that
 * users can edit before running, in case they need to fill in any of
 * the operational hooks.
 */
export function makeMigration(
  schema1,
  schema2,
  schemaChangeHandler = makeSchemaChangeHandler()
) {
  const { ignoreKey } = schemaChangeHandler;
  const operations = createDiff(schema1, schema2).filter(
    (op) => !ignoreKey(op.key)
  );

  if (operations.length === 0) {
    throw Errors.NOTHING_TO_MIGRATE;
  }

  // remove some values that have no meaning outside of the diffing process
  operations.forEach((op) => {
    delete op.stable;
    delete op.valueHash;
  });

  const version = schema1.__meta.version;

  const forwardChangeHandlers = operations
    .map((op) => {
      if (!op.fn) return ``;
      const dov = op.value?.default;
      const cleanKey = op.key.replaceAll(`.shape`, ``);
      return (
        `changeHandler.${op.fn} = ` +
        `function (data, op) {
  ${
    dov !== undefined
      ? `// data.${cleanKey} will be assigned its default value [${
          dov === `` ? `""` : dov
        }] after this function runs.`
      : `// Uncomment the follow line to make sure a valid default value gets assigned:\n  // data.${cleanKey} = ...`
  }
};
`
      );
    })
    .join(`\n`);

  const rollbackChangeHandlers = operations
    .map((op) => {
      if (!op.rollback) return ``;
      return (
        `changeHandler.${op.rollback} = ` +
        `function (data, op) {
  const value = data.${op.key};
  // Your "before rollback" code goes here.
};
`
      );
    })
    .join(`\n`);

  return `const howToRun = \`
Autogenerated executable runner for migrating data based on the
"${schema1.__meta.name}" schema from version ${version} to version ${
    version + 1
  }.
${
  !(forwardChangeHandlers || rollbackChangeHandlers)
    ? ``
    : `
A number of change handler functions have been included, which are called
during the migration process, and can be implemented to perform data
processing outside of the migration itself.`
}

Usage:

  1. node schemaName.vFrom.to.vNext.js targefile.json
  2. node schemaName.vFrom.to.vNext.js targefile.json --write
  3. node schemaName.vFrom.to.vNext.js targetdirectory --all

Mode 1: if a target file is indicated, the migration script will load in
the file and migrate its data, outputting the result to stdout

Mode 2: If the "--write" flag is provided, no data will be written to
stdout, instead rewriting the file itself in place.

Mode 3: If the "--all" flag is provided in combination with a directory
path, the script will load all .json files in the indicated directory and
process them as if running in mode 2.

Rollback usage:

  node schemaName.vFrom.to.vNext.js [...] --rollback

All three modes can be made to roll back a migration by using the
"--rollback" flag, which will rollback each step in the list of diff
operations, running them last-to-first.\`;

if (process.argv.length <= 2) {
  console.log(howToRun);
  process.exit(1);
}

${forwardChangeHandlers}

${rollbackChangeHandlers}

const operations = ${JSON.stringify(operations, false, 2)};

const datapath = process.argv[2];
const processAll = process.argv.includes("--all");
const writeInPlace = processAll || process.argv.includes("--write");

const rollback = process.argv.includes("--rollback");
if (rollback) reverseDiff(operations);

if (processAll) {
  fs.readdirSync(datapath)
    .filter(v => v.endsWith(".json"))
    .forEach(filepath => {
      console.log(filepath);
      processFile(datapath + "/" + filepath);
    });
} else processFile(datapath);

/**
 * ...
 */
function processFile(filename) {
  if (!fs.existsSync(filename)) {
    console.error(\`Could not find \${filename}\`);
    process.exit(1);
  }

  let data = fs.readFileSync(filename);

  try {
    data = JSON.parse(data.toString("utf-8"));
  } catch (e) {
    console.error(\`Could not parse \${filename} as JSON\`);
    process.exit(1);
  }

  const updated = applyDiff(operations, data, changeHandler);
  const newData = JSON.stringify(updated, false, 2);

  if (writeInPlace) {
    fs.writeFileSync(filename, newData);
  } else {
    console.log(newData);
  }
}

/**
 * ...
 */
${schemaChangeHandler.ignoreKey.toString()};

/**
 * ...
 */
${schemaChangeHandler.filterKeyString.toString()};

/**
 * ...
 */
${schemaChangeHandler.transformValue.toString()};

/**
 * ...
 */
${schemaChangeHandler.getObjectLevel.toString()};

/**
 * ...
 */
${schemaChangeHandler.toString()};


/**
 * ...
 */
${fromSchemaToData.toString()}

/**
 * ...
 */
${validateField.toString()}

/**
 * ...
 */
${applyDiff.toString()}

/**
 * ...
 */
${reverseDiff.toString()}
`;
}
